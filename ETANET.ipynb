{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "python: 3.7.12\n",
    "\n",
    "GPU: P100\n",
    "\n",
    "pytorch: 1.13.0\n",
    "\n",
    "transformers: 4.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import logging\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import psutil\n",
    "from tqdm import tqdm,trange\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "import argparse\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from transformers import BertConfig,BertTokenizer,BertModel,BertPreTrainedModel,AdamW,get_linear_schedule_with_warmup\n",
    "import os\n",
    "import math\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']=\"\" #if not use \"wandb\", please ignore \n",
    "os.environ['WANDB_MODE']=\"online\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_categorical_crossentropy(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    https://kexue.fm/archives/7359\n",
    "    \"\"\"\n",
    "  \n",
    "    y_true=F.one_hot(y_true)\n",
    "    y_true = y_true.float().detach()\n",
    "    y_pred = (1 - 2 * y_true) * y_pred  # -1 -> pos classes, 1 -> neg classes\n",
    "    y_pred_neg = y_pred - y_true * 1e12  # mask the pred outputs of pos classes\n",
    "    y_pred_pos = (y_pred - (1 - y_true) * 1e12)  # mask the pred outputs of neg classes\n",
    "    zeros = torch.zeros_like(y_pred[..., :1])\n",
    "    y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1)\n",
    "    y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1)\n",
    "    neg_loss = torch.logsumexp(y_pred_neg, dim=-1)\n",
    "    pos_loss = torch.logsumexp(y_pred_pos, dim=-1)\n",
    "    return (neg_loss + pos_loss).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biaffine(nn.Module):\n",
    "    def __init__(self, n_in, n_out=1, bias_x=True, bias_y=True):\n",
    "        super(Biaffine, self).__init__()\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.bias_x = bias_x\n",
    "        self.bias_y = bias_y\n",
    "        weight = torch.zeros(( n_in + int(bias_x),n_out, n_in + int(bias_y)))\n",
    "        nn.init.xavier_normal_(weight)\n",
    "        self.weight = nn.Parameter(weight, requires_grad=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if self.bias_x:\n",
    "            x = torch.cat((x, torch.ones_like(x[..., :1])), -1)\n",
    "        if self.bias_y:\n",
    "            y = torch.cat((y, torch.ones_like(y[..., :1])), -1)\n",
    "        # [batch_size, seq_len, seq_len, n_out]\n",
    "        s = torch.einsum('bxi,ioj,byj->bxyo', x, self.weight, y)\n",
    "        # remove dim 1 if n_out == 1\n",
    "        return s\n",
    "class MLPla(nn.Module):\n",
    "    def __init__(self,num_hiddens,out_size,active_fun=None):\n",
    "        super().__init__()\n",
    "        self.mlplayer=nn.Sequential(\n",
    "            nn.LayerNorm(num_hiddens),\n",
    "#             nn.BatchNorm1d(hidden_size, affine=False, track_running_stats=False),\n",
    "#             nn.Linear(num_hiddens,1024),\n",
    "#             nn.Softplus(),\n",
    "            nn.Linear(num_hiddens,out_size),\n",
    "            nn.GELU() if active_fun=='GELU' else nn.ReLU() if active_fun=='ReLU' else nn.Softplus() if active_fun=='Softplus' else nn.Sigmoid() if active_fun=='Sigmoid' else nn.Softmax()\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.mlplayer(X)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,num_hiddens,out_size,active_fun=None):\n",
    "        super().__init__()\n",
    "        self.mlplayer=nn.Sequential(\n",
    "#             nn.LayerNorm(num_hiddens),\n",
    "#             nn.Linear(num_hiddens,1024),\n",
    "#             nn.Softplus(),\n",
    "            nn.Linear(num_hiddens,out_size),\n",
    "            nn.GELU() if active_fun=='GELU' else nn.ReLU() if active_fun=='ReLU' else nn.Softplus() if active_fun=='Softplus' else nn.Sigmoid() if active_fun=='Sigmoid' else nn.Softmax()\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.mlplayer(X)\n",
    "class MLPnorm(nn.Module):\n",
    "    def __init__(self,num_hiddens,out_size,active_fun=None):\n",
    "        super().__init__()\n",
    "        self.banorm= nn.BatchNorm1d(num_hiddens*127)\n",
    "        self.linear=nn.Linear(num_hiddens,out_size)\n",
    "        self.active= nn.GELU() if active_fun=='GELU' else nn.ReLU() if active_fun=='ReLU' else nn.Softplus() if active_fun=='Softplus' else nn.Sigmoid() if active_fun=='Sigmoid' else nn.Softmax()\n",
    "    def forward(self,X):\n",
    "        dim=X.dim()\n",
    "        if dim==3:\n",
    "            B,L,H=X.size()\n",
    "        else:\n",
    "            B,L,L,H=X.size()\n",
    "        X=X.view(B,-1)\n",
    "        X1=self.banorm(X)\n",
    "        if dim==3:\n",
    "            X1=X1.view(B,L,H)\n",
    "        else:\n",
    "            X1=X1.view(B,L,L,H)\n",
    "        X2=self.linear(X1)\n",
    "        \n",
    "        X2=self.active(X2)\n",
    "        return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(nn.Module):\n",
    "    '''卷积层\n",
    "    '''\n",
    "    def __init__(self, input_size, channels=96, dilation=[1,2,3], dropout=0.0):\n",
    "        super(ConvolutionLayer, self).__init__()\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.Conv2d(input_size, channels, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "#             nn.Softplus(),\n",
    "        )\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(channels, channels, kernel_size=11, groups=channels, dilation=d, padding=5*d) for d in dilation])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        x = self.base(x)\n",
    "        outputs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "            x = F.gelu(x)\n",
    "            outputs.append(x)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        outputs = outputs.permute(0, 2, 3, 1).contiguous()\n",
    "        return outputs\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, input_dim, cond_dim=0, center=True, scale=True, epsilon=None, conditional=False,\n",
    "                 hidden_units=None, hidden_activation='linear', hidden_initializer='xaiver', **kwargs):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \"\"\"\n",
    "        input_dim: inputs.shape[-1]\n",
    "        cond_dim: cond.shape[-1]\n",
    "        \"\"\"\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.conditional = conditional\n",
    "        self.hidden_units = hidden_units\n",
    "        self.hidden_initializer = hidden_initializer\n",
    "        self.epsilon = epsilon or 1e-12\n",
    "        self.input_dim = input_dim\n",
    "        self.cond_dim = cond_dim\n",
    "\n",
    "        if self.center:\n",
    "            self.beta = nn.Parameter(torch.zeros(input_dim))\n",
    "        if self.scale:\n",
    "            self.gamma = nn.Parameter(torch.ones(input_dim))\n",
    "\n",
    "        if self.conditional:\n",
    "            if self.hidden_units is not None:\n",
    "                self.hidden_dense = nn.Linear(in_features=self.cond_dim, out_features=self.hidden_units, bias=False)\n",
    "            if self.center:\n",
    "                self.beta_dense = nn.Linear(in_features=self.cond_dim, out_features=input_dim, bias=False)\n",
    "            if self.scale:\n",
    "                self.gamma_dense = nn.Linear(in_features=self.cond_dim, out_features=input_dim, bias=False)\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "\n",
    "        if self.conditional:\n",
    "            if self.hidden_units is not None:\n",
    "                if self.hidden_initializer == 'normal':\n",
    "                    torch.nn.init.normal(self.hidden_dense.weight)\n",
    "                elif self.hidden_initializer == 'xavier':  # glorot_uniform\n",
    "                    torch.nn.init.xavier_uniform_(self.hidden_dense.weight)\n",
    "\n",
    "            if self.center:\n",
    "                torch.nn.init.constant_(self.beta_dense.weight, 0)\n",
    "            if self.scale:\n",
    "                torch.nn.init.constant_(self.gamma_dense.weight, 0)\n",
    "\n",
    "    def forward(self, inputs, cond=None):\n",
    "        if self.conditional:\n",
    "            if self.hidden_units is not None:\n",
    "                cond = self.hidden_dense(cond)\n",
    "\n",
    "            for _ in range(len(inputs.shape) - len(cond.shape)):\n",
    "                cond = cond.unsqueeze(1)  # cond = K.expand_dims(cond, 1)\n",
    "\n",
    "            if self.center:\n",
    "                beta = self.beta_dense(cond) + self.beta\n",
    "            if self.scale:\n",
    "                gamma = self.gamma_dense(cond) + self.gamma\n",
    "        else:\n",
    "            if self.center:\n",
    "                beta = self.beta\n",
    "            if self.scale:\n",
    "                gamma = self.gamma\n",
    "\n",
    "        outputs = inputs\n",
    "        if self.center:\n",
    "            mean = torch.mean(outputs, dim=-1).unsqueeze(-1)\n",
    "            outputs = outputs - mean\n",
    "        if self.scale:\n",
    "            variance = torch.mean(outputs ** 2, dim=-1).unsqueeze(-1)\n",
    "            std = (variance + self.epsilon) ** 0.5\n",
    "            outputs = outputs / std\n",
    "            outputs = outputs * gamma\n",
    "        if self.center:\n",
    "            outputs = outputs + beta\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InformationFusionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformationFusionLayer(nn.Module):\n",
    "    def __init__(self,type_size,num_hiddens,type_hiddens=768):\n",
    "        super(InformationFusionLayer,self).__init__()\n",
    "        self.type_embedding=nn.Embedding(type_size,type_hiddens)\n",
    "       \n",
    "        self.clnlayer=LayerNorm(num_hiddens,2*num_hiddens,conditional=True)\n",
    "\n",
    "        self.type_embedding.weight.requires_grad = True\n",
    "\n",
    "        self.mlp=MLP(type_hiddens,type_hiddens)\n",
    "    def forward(self,X,overlap_ids=None,attention_mask=None): #overlap_id[bs,length]\n",
    "\n",
    "        X_H=X.transpose(0,1)[1:].transpose(0,1)\n",
    "        trigger_word_vecs = []\n",
    "        tri_mask = overlap_ids.bool()\n",
    "        for i in range(X_H.size(0)):\n",
    "            # Extract the trigger word vectors for the i-th element in the batch\n",
    "            tri_mask_i = tri_mask[i]\n",
    "            trigger_word_vecs_i = X_H[i][tri_mask_i]\n",
    "\n",
    "            # Reshape and take the maximum along the first dimension\n",
    "            trigger_word_vecs_i = trigger_word_vecs_i.view(-1, X_H.size(-1))\n",
    "            trigger_word_vecs_i,_ = torch.max(trigger_word_vecs_i,dim=0) #[emb]\n",
    "\n",
    "            # Append the extracted trigger word vectors to the list\n",
    "            trigger_word_vecs.append(trigger_word_vecs_i)\n",
    "\n",
    "        # Concatenate the trigger word vectors for all elements in the batch\n",
    "        trigger_word_vecs = torch.stack(trigger_word_vecs, dim=0) #[bs,emb]\n",
    "#         query=self.linear(trigger_word_vecs)\n",
    "        score = torch.einsum('be,te->bt', trigger_word_vecs, self.type_embedding.weight)#[bs,ts]\n",
    "        _, max_indices = score.topk(k=2, dim=-1) #[bs,2]\n",
    "        \n",
    "        type_emb_list=[]\n",
    "        for i in range(X_H.size(0)):\n",
    "            if max(overlap_ids[i])>1:\n",
    "                idx=max_indices[i][1]\n",
    "            else:\n",
    "                idx=max_indices[i][0]\n",
    "            type_emb_list.append(self.mlp(self.type_embedding(idx)))\n",
    "        type_emb=torch.stack(type_emb_list,dim=0)#[bs,emb]\n",
    "        type_emb=type_emb.unsqueeze(1).expand_as(X_H)#[bs,1,emb]\n",
    "        trigger_word_vecs=trigger_word_vecs.reshape(X_H.shape[0],-1,X_H.shape[-1]).expand_as(X_H)\n",
    "        trigger_word_vecs=torch.cat((trigger_word_vecs,type_emb),dim=-1)\n",
    "        outputs_tr_ty=self.clnlayer(X_H,trigger_word_vecs) #[bs,length,emb]\n",
    "        return outputs_tr_ty,None #[bs,length-1,emd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JointPredictionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_pe(L):\n",
    "   \n",
    "    _arg_rpe = torch.zeros((L, L),dtype=torch.float32)\n",
    "    for k in range(L):\n",
    "        _arg_rpe[k, :] += k\n",
    "        _arg_rpe[:, k] -= k\n",
    "    P = torch.zeros((L,L))\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if j>i:\n",
    "                v =_arg_rpe[i][j]-9\n",
    "            elif j==i:\n",
    "                v=_arg_rpe[i][j]-19\n",
    "            else:\n",
    "                v=_arg_rpe[i][j]\n",
    "            w= 1 / (1000 ** (v / L))\n",
    "            if v % 2 == 0:\n",
    "                P[i,j] =torch.sin(w * i)\n",
    "            else:\n",
    "                P[i,j] = torch.cos(w * i)\n",
    "    return P\n",
    "\n",
    "class JointPredictionLayer(nn.Module):\n",
    "    def __init__(self,num_hiddens,span_size,relation_size,active_fun,mlp_name=None):\n",
    "        super().__init__()\n",
    "        self.dis_embs = nn.Embedding(20, 20)\n",
    "        self.reg_embs = nn.Embedding(3, 20)\n",
    "        self.reg_embs1 = nn.Embedding(4, 20)\n",
    "        self.span_size=span_size\n",
    "        self.relation_size=relation_size\n",
    "\n",
    "        self.span_cln = LayerNorm(num_hiddens,num_hiddens,conditional=True)\n",
    "        self.relation_cln = LayerNorm(num_hiddens,num_hiddens,conditional=True)\n",
    "        \n",
    "        self.sconvLayer = ConvolutionLayer(20+20+num_hiddens,96)\n",
    "        self.rconvLayer = ConvolutionLayer(20+20+num_hiddens,96)\n",
    "        \n",
    "\n",
    "        self.S1_mlplayer=globals()[mlp_name](num_hiddens,4,active_fun='Sigmoid')\n",
    "        self.spans_mlpayer=globals()[mlp_name](num_hiddens+2,512,active_fun)\n",
    "        self.spane_mlpayer=globals()[mlp_name](num_hiddens+2,512,active_fun)\n",
    "\n",
    "        self.R1_mlplayer=globals()[mlp_name](num_hiddens,4,active_fun='Sigmoid')\n",
    "        self.relations_mlpayer=globals()[mlp_name](num_hiddens+4,512,active_fun)\n",
    "        self.relatione_mlpayer=globals()[mlp_name](num_hiddens+127,512,active_fun)\n",
    "\n",
    "        \n",
    "        self.spe1_mlpayer=globals()[mlp_name](127+512,512,active_fun)\n",
    "        self.spe2_mlpayer=globals()[mlp_name](127+512,512,active_fun)\n",
    "        self.rpe1_mlpayer=globals()[mlp_name](127+512,512,active_fun)\n",
    "        self.rpe2_mlpayer=globals()[mlp_name](127+512,512,active_fun)\n",
    "        \n",
    "\n",
    "        self.SCLN_mlplayer=globals()[mlp_name](3*96,288,active_fun)\n",
    "        self.RCLN_mlplayer=globals()[mlp_name](3*96,288,active_fun)\n",
    "\n",
    "        self.S_biaffine=Biaffine(512,span_size)\n",
    "        self.R_biaffine=Biaffine(512,relation_size)\n",
    "        self.W_relation = nn.Parameter(torch.randn(num_hiddens,num_hiddens),requires_grad = True)\n",
    "        self.dropout=nn.Dropout(p=args.dropout_p)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "        self.Wr=nn.Linear(288,relation_size,active_fun)\n",
    "        self.Ws=nn.Linear(288,span_size,active_fun)\n",
    "        self.P=get_arg_pe(L=127)\n",
    "        \n",
    "    def forward(self,X,Y,_dist_inputs,orlp_ids,span_labels): #[bs,length,emd]\n",
    "#         assert X_info1.shape[1]==Y_info1.shape[1]==127,print(X_info1.shape,Y_info1.shape)\n",
    "        \n",
    "        span_grid_mask2d=(span_labels!=-1)\n",
    "\n",
    "        tril_mask = torch.tril(span_grid_mask2d.clone().long())\n",
    "        reg_inputs = tril_mask + span_grid_mask2d.clone().long()\n",
    "\n",
    "        reg_emb = self.reg_embs(reg_inputs)\n",
    "        dis_emb = self.dis_embs(_dist_inputs)\n",
    "        \n",
    "        \n",
    "        span_cln=self.span_cln(X.unsqueeze(2),X)\n",
    "        span_conv_inputs = torch.cat([dis_emb, reg_emb, span_cln], dim=-1)\n",
    "        span_conv_inputs[span_labels==-1]=0\n",
    "        span_conv_outputs=self.sconvLayer(span_conv_inputs)\n",
    "        span_conv_outputs[span_labels==-1]=0\n",
    "        cln_span=self.SCLN_mlplayer(self.dropout(span_conv_outputs))\n",
    "        cln_span_logits=self.Ws(cln_span)\n",
    "        \n",
    "        orlp_inputs=orlp_ids.unsqueeze(1).expand_as(span_grid_mask2d).clone()\n",
    "        \n",
    "        tril_mask1 = torch.tril(span_grid_mask2d.clone().long())\n",
    "        reg_inputs1 = tril_mask1 + span_grid_mask2d.clone().long()\n",
    "        \n",
    "        reg_inputs1[orlp_inputs>0]=3\n",
    "        reg_inputs1[span_labels==-1]=0\n",
    "\n",
    "        \n",
    "        reg_emb1=self.reg_embs1(reg_inputs1)\n",
    "        relation_cln=self.relation_cln(Y.unsqueeze(2),Y)\n",
    "\n",
    "             \n",
    "        relation_conv_inputs = torch.cat([dis_emb,reg_emb1,relation_cln], dim=-1)  \n",
    "        relation_conv_inputs[span_labels==-1]=0\n",
    "        relation_conv_outputs=self.rconvLayer(relation_conv_inputs)\n",
    "        relation_conv_outputs[span_labels==-1]=0\n",
    "        cln_relation=self.RCLN_mlplayer(self.dropout(relation_conv_outputs))\n",
    "        cln_relation_logits=self.Wr(cln_relation)\n",
    "        \n",
    "\n",
    "\n",
    "        P=self.P.unsqueeze(0).expand(X.shape[0], -1, -1)\n",
    "        rp_emb=P.to(X.device)\n",
    "        X_args=self.S1_mlplayer(self.dropout(X))#[,4]\n",
    "\n",
    "        X_arg_start, X_arg_end = torch.chunk(X_args, 2, dim=-1)#[,2]\n",
    "        \n",
    "        X_span_start=torch.cat((X,X_arg_start),dim=-1)#[,768+2]\n",
    "        X_span_end=torch.cat((X,X_arg_end),dim=-1)\n",
    "        \n",
    "        X_info_span1=self.spans_mlpayer(self.dropout(X_span_start))#[,512]\n",
    "        X_info_span2=self.spane_mlpayer(self.dropout(X_span_end))\n",
    "        X_info_span1=torch.cat((X_info_span1,rp_emb),dim=-1)#[,256+512]\n",
    "        X_info_span2=torch.cat((X_info_span2,rp_emb),dim=-1)\n",
    "        X_info_s1=self.spe1_mlpayer(X_info_span1)\n",
    "        X_info_s2=self.spe2_mlpayer(X_info_span2)\n",
    "        \n",
    "        Y_args=self.R1_mlplayer(self.dropout(Y))\n",
    "\n",
    "        Y_arg_start, Y_arg_end = torch.chunk(Y_args, 2, dim=-1)\n",
    "\n",
    "        X_info_arg=torch.cat((X,Y_arg_start,Y_arg_end),dim=-1)#[,768+2+2]\n",
    "\n",
    "\n",
    "        Y_info_real1=self.relations_mlpayer(self.dropout(X_info_arg))#[,512]\n",
    "        Y_info_real1=torch.cat((Y_info_real1,rp_emb),dim=-1)\n",
    "        Y_info_r1=self.rpe1_mlpayer(Y_info_real1)\n",
    "        \n",
    "        Y_info_arg=torch.einsum('bxi,ij,byj->bxy', X, self.W_relation, X)#[,127,127]\n",
    "        Y_info_r=self.sigmoid(self.dropout(Y_info_arg))\n",
    "        Y_info_r=torch.cat((X,Y_info_r),dim=-1)#[,768+127]\n",
    "\n",
    "\n",
    "        Y_info_real2=self.relatione_mlpayer(self.dropout(Y_info_r))#[,512]\n",
    "        Y_info_real2=torch.cat((Y_info_real2,rp_emb),dim=-1)\n",
    "        Y_info_r2=self.rpe2_mlpayer(Y_info_real2)\n",
    "  \n",
    "\n",
    "        #bilinar_classifer\n",
    "        bilinar_span_logits=self.S_biaffine(X_info_s1,X_info_s2)\n",
    "        bilinar_relation_logits=self.R_biaffine(Y_info_r1,Y_info_r2)\n",
    "\n",
    "                      \n",
    "        #span_logits:[bs,(length-1),(length-1),span_size] relation_logits:[bs,(length-1),(length-1),relation_size]\n",
    "        return bilinar_span_logits+cln_span_logits,bilinar_relation_logits+cln_relation_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTETANET(BertPreTrainedModel):\n",
    "    def __init__(self,config,num_hiddens,type_size,span_size,relation_size,loss_name,active_fun=None,mlp_name=None,weights=None):\n",
    "        super().__init__(config)\n",
    "        self.bert=BertModel.from_pretrained('bert-base-multilingual-cased',config=config)\n",
    "\n",
    "        self.tri_rpe_embed=nn.Embedding(128,20)\n",
    "\n",
    "        self.mlplayer=globals()[mlp_name](num_hiddens+20,num_hiddens,active_fun)\n",
    "        \n",
    "\n",
    "        self.infofulayer=InformationFusionLayer(type_size,num_hiddens)\n",
    "\n",
    "        self.predlayer=JointPredictionLayer(num_hiddens,span_size,relation_size,active_fun,mlp_name)\n",
    "        self.span_size=span_size\n",
    "        self.relation_size=relation_size\n",
    "        self.loss_name=loss_name\n",
    "        self.s_weight,self.r_weight=weights\n",
    "\n",
    "    def forward(self,input_ids=None,attention_mask=None,token_type_ids=None, position_ids=None, \\\n",
    "                head_mask=None, inputs_embeds=None,span_labels=None,relation_labels=None,overlap_ids=None,_dist_inputs=None,_tir_rpe=None):\n",
    "\n",
    "        bert_embs =self.bert(                 # [bs, length, emd] \n",
    "            input_ids,                      # [batch,length]\n",
    "            attention_mask=attention_mask,  # padding\n",
    "            token_type_ids=token_type_ids,  # sentence segmentation\n",
    "            position_ids=position_ids,      # position emebedding\n",
    "            head_mask=head_mask,            # ？\n",
    "            inputs_embeds=inputs_embeds,    # lookup mat\n",
    "        )\n",
    "        outputs = bert_embs[0]\n",
    "\n",
    "        \n",
    "        info_outs,tri_logits = self.infofulayer(outputs,overlap_ids,attention_mask) #[bs,length-1,num_hiddens]\n",
    "\n",
    "        orlp_ids=(overlap_ids!=-1).clone().unsqueeze(-1)\n",
    "        \n",
    "        loss_t=None\n",
    "        if tri_logits != None:\n",
    "            \n",
    "            orlp_ids[orlp_ids>0]=1\n",
    "            tri_logits=tri_logits[orlp_ids!=-1]\n",
    "            orlp_ids=orlp_ids[orlp_ids!=-1]\n",
    "            loss_t=multilabel_categorical_crossentropy(tri_logits,orlp_ids)\n",
    "        tri_rpe_input=self.tri_rpe_embed(_tir_rpe)#[bs,length,20]\n",
    "        outputs_tri_pe=torch.cat((info_outs,tri_rpe_input),dim=-1)\n",
    "\n",
    "        outputs_tri=outputs_tri_pe*orlp_ids\n",
    "\n",
    "        outputs1=self.mlplayer(outputs_tri)\n",
    "        \n",
    "        outputs2=outputs1*orlp_ids\n",
    "\n",
    "        span_logits,relation_logits=self.predlayer(outputs2,outputs2,_dist_inputs,overlap_ids,span_labels)\n",
    "        span_label_mask = (span_labels != -1).clone() #[bs,length-1,length-1]\n",
    "        relation_label_mask = (relation_labels != -1).clone()\n",
    "\n",
    "        if span_labels !=None:\n",
    "            span_outs = span_logits[span_label_mask]\n",
    "            span_label = span_labels[span_label_mask]\n",
    "            \n",
    "            relation_outs = relation_logits[relation_label_mask]\n",
    "            relation_label = relation_labels[relation_label_mask]\n",
    "\n",
    "            loss_s=multilabel_categorical_crossentropy(span_outs,span_label)\n",
    "\n",
    "            loss_r=multilabel_categorical_crossentropy(relation_outs,relation_label)\n",
    "\n",
    "            if loss_t != None:\n",
    "                loss = loss_t+loss_s+loss_r\n",
    "            else:\n",
    "\n",
    "                loss=self.s_weight*loss_s+self.s_weight*loss_r\n",
    "            return (loss,)+(span_logits,relation_logits)\n",
    "        \n",
    "        return (span_logits,relation_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    def __init__(self,example_id,content,overlap_id,span_label,relation_label,):\n",
    "        self.example_id=example_id\n",
    "        self.content=content\n",
    "        self.overlap_id=overlap_id\n",
    "        self.span_label=span_label\n",
    "        self.relation_label=relation_label\n",
    "        \n",
    "class InputFeatures(object):\n",
    "    def __init__(self,example_id,input_ids,attention_mask,overlap_id,span_label,relation_label,_dist_inputs,_tir_rpe,):\n",
    "        self.example_id=example_id\n",
    "        self.attention_mask=attention_mask\n",
    "        self.input_ids=input_ids\n",
    "        self.overlap_id=overlap_id\n",
    "        self.span_label=span_label\n",
    "        self.relation_label=relation_label\n",
    "        self._dist_inputs=_dist_inputs\n",
    "        self._tir_rpe=_tir_rpe\n",
    "        \n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_MI_examples(self,data_dir):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _create_examples(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class FewFCProcessor(DataProcessor):\n",
    "    def get_train_examples(self,data_dir):\n",
    "        datas=[]\n",
    "        file1=open(os.path.join(data_dir,'train_labels.json'),\"r\")\n",
    "\n",
    "        for line in file1:\n",
    "            datas.append(json.loads(line))\n",
    "\n",
    "        return self._create_examples(datas,'train')\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        datas=[]\n",
    "        file1=open(os.path.join(data_dir,'dev_labels.json'),\"r\")\n",
    "\n",
    "        for line in file1:\n",
    "            datas.append(json.loads(line))\n",
    "\n",
    "        return self._create_examples(datas,'dev')\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n",
    "        raise None\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        return ['None','S','T'],['None','R']\n",
    "    def _create_examples(self,lines,set_type):\n",
    "        examples=[]\n",
    "        for data in lines:\n",
    "            e_id = \"%s-%s\" % (set_type, str(data['id']))\n",
    "            indices,values,size=data['span_label'][0],data['span_label'][1],data['span_label'][2]\n",
    "            span_label=torch.sparse_coo_tensor(indices,values,size).to_dense()#转成稠密矩阵\n",
    "            \n",
    "            indices,values,size=data['relation_label'][0],data['relation_label'][1],data['relation_label'][2]\n",
    "            relation_label=torch.sparse_coo_tensor(indices,values,size).to_dense()#转成稠密矩阵\n",
    "            \n",
    "            examples.append(InputExample(\n",
    "                example_id=e_id,\n",
    "                content=data['content'],\n",
    "                overlap_id=data['overlap_ids'],\n",
    "                span_label=span_label,\n",
    "                relation_label=relation_label,\n",
    "                \n",
    "            ))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相对距离设置\n",
    "dis2idx = np.zeros((1000), dtype='int64')\n",
    "dis2idx[1] = 1\n",
    "dis2idx[2:] = 2\n",
    "dis2idx[4:] = 3\n",
    "dis2idx[8:] = 4\n",
    "dis2idx[16:] = 5\n",
    "dis2idx[32:] = 6\n",
    "dis2idx[64:] = 7\n",
    "dis2idx[128:] = 8\n",
    "dis2idx[256:] = 9\n",
    "def convert_examples_to_features(examples,label_list,max_length,tokenizer):\n",
    "    features = []\n",
    "   \n",
    "    for example in tqdm(examples,desc=\"convert examples to features\"):\n",
    "        inputs=tokenizer.encode_plus(example.content,add_special_tokens=True,max_length=max_length,padding='max_length',truncation=True)\n",
    "        inputs_ids,attention_mask=inputs['input_ids'],inputs['attention_mask'] #padding inputs\n",
    "\n",
    "        overlap_id=torch.tensor(example.overlap_id)\n",
    "        assert (overlap_id>0).sum()>0,print((overlap_id>0).sum(),example.example_id)\n",
    "        length=len(overlap_id)\n",
    "        overlap_id=F.pad(overlap_id,pad=(0,max_length-len(example.overlap_id)-1),value=-1)#padding overlap_id但去掉[cls]\n",
    "        #trigger的相对位置编码\n",
    "        _tri_index=torch.argwhere(overlap_id>0)\n",
    "        _tri_start,_tri_end=min(_tri_index),max(_tri_index)\n",
    "        _tri_start,_tri_end=_tri_start.item(),_tri_end.item()\n",
    "        pos=list(range(-_tri_start, 0)) + [0] * (_tri_end - _tri_start + 1) + list(range(1, length - _tri_end))\n",
    "        pos=[abs(x) for x in pos]\n",
    "        _tir_rpe=torch.tensor(pos)\n",
    "        _tir_rpe=F.pad(_tir_rpe,pad=(0,max_length-len(example.overlap_id)-1),value=max_length-1)\n",
    "             \n",
    "        #词对的相对位置编码\n",
    "        _dist_inputs = np.zeros((length, length),dtype=np.int64)\n",
    "        for k in range(length):\n",
    "            _dist_inputs[k, :] += k\n",
    "            _dist_inputs[:, k] -= k\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                if _dist_inputs[i, j] < 0:\n",
    "                    _dist_inputs[i, j] = dis2idx[-_dist_inputs[i, j]] + 9\n",
    "                else:\n",
    "                    _dist_inputs[i, j] = dis2idx[_dist_inputs[i, j]]\n",
    "            _dist_inputs[_dist_inputs == 0] = 19\n",
    "        \n",
    "        assert (_dist_inputs>19).sum()==0,print(_dist_inputs)\n",
    "        _dist_inputs=torch.as_tensor(_dist_inputs)   \n",
    "    \n",
    "        _dist_inputs=F.pad(_dist_inputs,pad=(0,max_length-len(example.overlap_id)-1,0,max_length-len(example.overlap_id)-1),value=0)\n",
    "#         assert overlap_id!=torch.zeros(len(overlap_id)),ValueError(\"overlap_id is zero tensor\")\n",
    "        #label padding\n",
    "        \n",
    "        extend_label_s=F.pad(example.span_label,pad=(0,max_length-len(example.span_label)-1,0,max_length-\\\n",
    "                                                     len(example.span_label)-1),value=-1)\n",
    "        relation_label=example.relation_label.transpose(1,0)\n",
    "        \n",
    "        extend_label_r=F.pad(relation_label,pad=(0,max_length-len(example.relation_label)-1,0,max_length-\\\n",
    "                                                         len(example.relation_label)-1),value=-1)\n",
    "\n",
    "        features.append(InputFeatures(example.example_id,inputs_ids,attention_mask,overlap_id,\\\n",
    "                                      extend_label_s,extend_label_r,_dist_inputs,_tir_rpe,))\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, task, tokenizer, evaluate=False, test=False):\n",
    "    processor = processors[task]()\n",
    "    label_list = processor.get_labels()\n",
    "    # Load data features from cache or dataset file\n",
    "    if evaluate:\n",
    "        cached_mode = \"dev\"\n",
    "    elif test:\n",
    "        cached_mode = \"test\"\n",
    "    else:\n",
    "        cached_mode = \"train\"\n",
    "        \n",
    "    #存储特征\n",
    "    cached_features_file = os.path.join(\n",
    "        features_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            cached_mode,\n",
    "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(task),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "#     if evaluate:\n",
    "#         cached_features_file=\"/kaggle/input/fewdataset2/cached_dev_bert-base-multilingual-cased_fewfc\"\n",
    "#     elif test:\n",
    "#         pass\n",
    "#     else:\n",
    "#         cached_features_file='/kaggle/input/fewdataset2/cached_train_bert-base-multilingual-cased_fewfc'\n",
    "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        print(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        label_list = processor.get_labels()\n",
    "        if evaluate:\n",
    "            examples = processor.get_dev_examples(args.data_dir)\n",
    "        elif test:\n",
    "            examples = processor.get_test_examples(args.data_dir)\n",
    "        else:\n",
    "            examples = processor.get_train_examples(args.data_dir)\n",
    "            \n",
    "        logger.info(\"Training number: %s\", str(len(examples)))\n",
    "            #检测数据转成features所占内存\n",
    "        features=convert_examples_to_features(examples,label_list,args.max_seq_length,tokenizer)   \n",
    "        if args.local_rank in [-1, 0]:\n",
    "                logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "                torch.save(features, cached_features_file)\n",
    "    # Convert to Tensors and build dataset\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_overlap_ids = torch.tensor([f.overlap_id.tolist() for f in features], dtype=torch.long)\n",
    "    all_span_labels = torch.tensor([f.span_label.tolist() for f in features], dtype=torch.long)\n",
    "    all_dist_inputs = torch.tensor([f._dist_inputs.tolist() for f in features], dtype=torch.long)\n",
    "    all_tir_rpe = torch.tensor([f._tir_rpe.tolist() for f in features], dtype=torch.long)\n",
    "    all_relation_labels=torch.tensor([f.relation_label.tolist() for f in features], dtype=torch.long)\n",
    "    \n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_overlap_ids,\\\n",
    "                            all_span_labels,all_relation_labels,all_dist_inputs,all_tir_rpe,)\n",
    "    if evaluate or test:\n",
    "        return dataset, [f.example_id for f in features]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "def train(config,args, train_dataset, tokenizer):\n",
    "    model = BERTETANET(config,args.hidden_size,args.type_num,3,2,args.loss_name,args.active_fun,args.mlp_name,(args.loss_s_weight,args.loss_r_weight))\n",
    "    model.to(args.device)\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu) #8*2=16   \n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "      \n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "    \n",
    "    # Prepare optimizer and schedule (linear warmup and decay) #####################################################\n",
    "    \n",
    "    #继续恢复训练##############################################################################\n",
    "#     output_train_checkpoint_dir= os.path.join(args.output_dir,'train_checkpoint')\n",
    "#     max_epoch=-1\n",
    "#     if os.path.exists(output_train_checkpoint_dir):\n",
    "#         checkpoint_path=os.listdir(output_train_checkpoint_dir)\n",
    "# #         print('checkpoint_path:',checkpoint_path)\n",
    "#         for checkpoint in checkpoint_path:\n",
    "#             s=int(checkpoint.split('-')[-1].split('.')[0])\n",
    "#             if s >max_epoch:\n",
    "#                 max_epoch=s\n",
    "#     else:\n",
    "#         os.makedirs(output_train_checkpoint_dir)\n",
    "        \n",
    "#     model_path = os.path.join(output_train_checkpoint_dir,\"checkpoint_epoch-{}.pt\".format(max_epoch))\n",
    "#     if os.path.exists(model_path):\n",
    "#         checkpoint = torch.load(model_path)\n",
    "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         print(\"Successfully loaded checkpoint from epoch {}\".format(epoch))\n",
    "#     else:\n",
    "#     bert_params = set(model.bert.parameters())\n",
    "#     other_params = list(set(model.parameters()) - bert_params)\n",
    "#     no_decay = ['bias', 'LayerNorm.weight']\n",
    "#     optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in model.bert.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#          'lr': args.bert_lr,\n",
    "#          'weight_decay': args.weight_decay},\n",
    "#         {'params': [p for n, p in model.bert.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#          'lr': args.bert_lr,\n",
    "#          'weight_decay': 0.0},\n",
    "#         {'params': other_params,\n",
    "#          'lr': args.learning_rate,\n",
    "#          'weight_decay': args.weight_decay},\n",
    "#     ]   \n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]   \n",
    "    optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'lr': args.learning_rate,\n",
    "                \"weight_decay\": args.weight_decay,\n",
    "            },\n",
    "            {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],'lr': args.learning_rate,\"weight_decay\": 0.0},\n",
    "        ] #采用weight_decay策略或不采用\n",
    "\n",
    "    optimizer = torch.optim.__dict__[args.optim_type](optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "        \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=args.warmup_ratio*t_total, num_training_steps=t_total,\n",
    "        )\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "        \n",
    "     # multi-gpu training (should be after apex fp16 initialization)################################\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    ########################################################################################### Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    \n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "    wandb.init(project='ETANET',config=args.__dict__)\n",
    "    model.run_id=wandb.run.id\n",
    "    wandb.watch(model,log='all')\n",
    "#     params_to_watch = list(model.infofulayer.parameters()) + list(model.predlayer.parameters())\n",
    "#     print(params_to_watch)\n",
    "#     wandb.watch(params_to_watch)\n",
    "#     wandb_config=wandb.config\n",
    "    #################################################################################################\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss,epoch_loss = 0.0, 0.0,0.0\n",
    "    best_dev_tif1 = 0.0\n",
    "    best_dev_aif1 = 0.0\n",
    "    best_steps = 0\n",
    "    best_dev_span_preds = []\n",
    "    best_dev_relation_preds = []\n",
    "    best_test_preds = []\n",
    "    \n",
    "    \n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    set_seed(args)  # Added here for reproductibility\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        model.train()\n",
    "        temp_step=0\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            temp_step=temp_step+1\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"overlap_ids\": batch[2],\n",
    "                \"span_labels\": batch[3],\n",
    "                \"relation_labels\":batch[4],\n",
    "                \"_dist_inputs\": batch[5],\n",
    "                \"_tir_rpe\": batch[6],\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            \n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "                \n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item() #累计误差\n",
    "            #累计计算梯度\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "                print('loss:',loss,optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                #进行评估\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    if (args.local_rank == -1 and args.evaluate_during_training):\n",
    "                        \n",
    "#                         results, dev_pred_span_results = evaluate(args, model, tokenizer)\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "\n",
    "#                         if results[\"eval_ti_f1\"] > best_dev_tif1:\n",
    "#                             best_dev_tif1=results[\"eval_ti_f1\"]\n",
    "#                             best_steps = global_step\n",
    "# #                             best_dev_span_preds = dev_pred_span_results\n",
    "#                             logger.info(\n",
    "#                                 \"eval_ti_f1: %s,loss: %s,glob steps: %s\",\n",
    "#                                 str(results[\"eval_ti_f1\"]),\n",
    "#                                 str(results[\"eval_loss\"]),\n",
    "#                                 str(global_step),\n",
    "#                             )\n",
    "                        if results[\"eval_ai_f1\"] > best_dev_aif1:\n",
    "                            best_dev_aif1=results[\"eval_ai_f1\"]\n",
    "                            best_steps = global_step\n",
    "#                             best_dev_relarion_preds = dev_pred_relation_results\n",
    "#                             logger.info(\n",
    "#                                 \"eval_ai_f1: %s,loss: %s,glob steps: %s\",\n",
    "#                                 str(results[\"eval_ai_f1\"]),\n",
    "#                                 str(results[\"eval_loss\"]),\n",
    "#                                 str(global_step),\n",
    "#                             )\n",
    "                        wandb.log({'eval_ai_f1':results[\"eval_ai_f1\"],'best_eval_ai_f1':best_dev_aif1,'best_steps':best_steps})\n",
    "                        wandb.log({'eval_loss':results[\"eval_loss\"]})\n",
    "                        wandb.log({'average_train_loss':(tr_loss - logging_loss) / args.logging_steps,'lr':optimizer.state_dict()['param_groups'][0]['lr']})\n",
    "#                 print('Average loss:',(tr_loss - logging_loss) / args.logging_steps,'at global step:',global_step)\n",
    "#                 logger.info(\n",
    "#                         \"Average loss: %s at global step: %s\",\n",
    "#                         str((tr_loss - logging_loss) / args.logging_steps),\n",
    "#                         str(global_step),\n",
    "#                     )\n",
    "                logging_loss = tr_loss\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        wandb.log({'train_loss':tr_loss-epoch_loss / temp_step})\n",
    "        epoch_loss=tr_loss\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "#         if epoch % 30 == 0:\n",
    "#             output_train_checkpoint_dir= os.path.join(args.output_dir,'train_checkpoint')\n",
    "#             if not os.path.exists(output_train_checkpoint_dir):\n",
    "#                 os.makedirs(output_train_checkpoint_dir)\n",
    "#             checkpoint_path = os.path.join(output_train_checkpoint_dir,\"checkpoint_epoch-{}.pt\".format(epoch))\n",
    "#             torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict()\n",
    "#         }, checkpoint_path)\n",
    "#     batch_size = args.per_gpu_train_batch_size\n",
    "#     seq_length = 128\n",
    "#     input_ids = torch.zeros(batch_size, seq_length, dtype=torch.long)\n",
    "#     onnx_model=torch.onnx.export(model,input_ids,\"model.onnx\")\n",
    "#     wandb.save(onnx_model)\n",
    "    wandb.finish()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, prefix=\"\", test=False):\n",
    "    eval_task_names = (args.task_name,)\n",
    "    eval_outputs_dirs = (args.output_dir,)\n",
    "\n",
    "    results = {}\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "        eval_dataset, eval_ids = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True, test=test)\n",
    "\n",
    "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "            os.makedirs(eval_output_dir)\n",
    "\n",
    "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "        # Note that DistributedSampler samples randomly\n",
    "        eval_sampler = RandomSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "        \n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "        \n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        span_preds_result=None\n",
    "        span_preds = None\n",
    "        span_preds_result=None\n",
    "        relation_preds=None\n",
    "        model.eval()\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"overlap_ids\": batch[2],\n",
    "                \"span_labels\": batch[3],#[bs,len-1,len-1]\n",
    "                \"relation_labels\":batch[4],\n",
    "                \"_dist_inputs\": batch[5],\n",
    "                \"_tir_rpe\": batch[6],\n",
    "                \n",
    "            }\n",
    "                temp_eval_loss,span_logits,relation_logits = model(**inputs)\n",
    "#                 temp_eval_loss,span_logits, = model(**inputs)\n",
    "    \n",
    "                span_label_mask=(inputs['span_labels']!= -1)\n",
    "                relation_label_mask=(inputs['relation_labels']!= -1)\n",
    "                eval_loss += temp_eval_loss.item()\n",
    "\n",
    "                temp_span_pred=None\n",
    "                temp_relation_pred=None\n",
    "                if span_preds is None:\n",
    "                    span_preds = span_logits[span_label_mask] #2D [-1,span_size]\n",
    "                    span_labels = inputs['span_labels'][span_label_mask] #1D\n",
    "                    relation_preds = relation_logits[relation_label_mask] #2D [-1,span_size]\n",
    "                    relation_labels = inputs['relation_labels'][relation_label_mask] #1D\n",
    "\n",
    "                    span_preds_result=torch.argmax(span_logits, dim=-1) #[bs,lne-1.len-1]\n",
    "                    span_preds_result[span_label_mask==False]=-1\n",
    "                    relation_preds_result=torch.argmax(relation_logits, dim=-1) #[bs,lne-1.len-1]\n",
    "                    relation_preds_result[relation_label_mask==False]=-1\n",
    "                else:\n",
    "                    #将其展开用于计算precison,reall,f1\n",
    "                    span_preds = torch.cat((span_preds, span_logits[span_label_mask]), axis=0)\n",
    "                    span_labels = torch.cat((span_labels, inputs['span_labels'][span_label_mask]), axis=0)\n",
    "                    relation_preds = torch.cat((relation_preds, relation_logits[relation_label_mask]), axis=0)\n",
    "                    relation_labels = torch.cat((relation_labels, inputs['relation_labels'][relation_label_mask]), axis=0)\n",
    "                    #未展开的用于进行预测和decoding\n",
    "#                     temp_span_pred=torch.argmax(span_logits, dim=-1)\n",
    "#                     temp_span_pred[span_label_mask==False]=-1 #填充部分的预测标记为-1\n",
    "#                     span_preds_result=torch.cat((span_preds_result,temp_span_pred), axis=0)\n",
    "                    \n",
    "              \n",
    "            nb_eval_steps += 1     \n",
    "        span_preds=torch.argmax(span_preds, dim=-1) #1D\n",
    "        relation_preds=torch.argmax(relation_preds, dim=-1) #1D\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "        ti_p,ti_r,ti_f1,ai_p,ai_r,ai_f1=calculate_scores(span_preds.detach().cpu().numpy(),span_labels.detach().cpu().numpy())\n",
    "\n",
    "        result = {\"eval_ti_precision\": ti_p, \"eval_ti_recall\": ti_r, \"eval_ti_f1\": ti_f1,\"eval_ai_precision\": ai_p,\\\n",
    "                  \"eval_ai_recall\": ai_r, \"eval_ai_f1\": ai_f1, \"eval_loss\": eval_loss}\n",
    "     \n",
    "        results.update(result)\n",
    "    return results\n",
    "#     return results, dict(list(zip(eval_ids,span_preds_result)))\n",
    "\n",
    "\n",
    "\n",
    "def calculate_scores(pred_span_labels,span_labels,pred_relation_labels=None,relation_labels=None):\n",
    "    # TI: Trigger Identification\n",
    "    ti_correct = ((pred_span_labels == 2) & (span_labels == pred_span_labels)).sum()\n",
    "    ti_total_pred = (pred_span_labels == 2).sum()\n",
    "    ti_total_gold = (span_labels == 2).sum()\n",
    "\n",
    "    ti_precision = ti_correct / ti_total_pred if ti_total_pred else 0\n",
    "    ti_recall = ti_correct / ti_total_gold if ti_total_gold else 0\n",
    "    ti_f1 = 2 * ti_precision * ti_recall / (ti_precision + ti_recall) if ti_precision + ti_recall else 0\n",
    "\n",
    "    # AI: Argument Identification\n",
    "    ai_correct = ((pred_span_labels == 1) & (span_labels==pred_span_labels)).sum()\n",
    "    ai_total_pred = (pred_span_labels == 1).sum()\n",
    "    ai_total_gold = (span_labels == 1).sum()\n",
    "\n",
    "    ai_precision = ai_correct / ai_total_pred if ai_total_pred else 0\n",
    "    ai_recall = ai_correct / ai_total_gold if ai_total_gold else 0\n",
    "    ai_f1 = 2 * ai_precision * ai_recall / (ai_precision + ai_recall) if ai_precision + ai_recall else 0\n",
    "\n",
    "    return ti_precision, ti_recall, ti_f1, ai_precision, ai_recall, ai_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_dir='/kaggle/working/'\n",
    "processors={\"fewfc\": FewFCProcessor}\n",
    "TYPE_SIZE=30\n",
    "NUM_HIDDENS=768\n",
    "MODEL_CLASSES = {'bert':(BertConfig, BertModel, BertTokenizer)}\n",
    "logger = logging.getLogger(__name__)\n",
    "sweep_config={'method':\"random\"}\n",
    "metric={'name':'eval_ai_f1','goal':'maximize'}\n",
    "sweep_config['metric']=metric\n",
    "sweep_config['parameters']={}\n",
    "sweep_config['parameters'].update({\n",
    "    'project_name':{'value':'ETANET'},\n",
    "#     'num_train_epochs':{\"value\":6},\n",
    "    'optim_type':{'values':['Adamw','AdaDelta','AdaDeltaW','Adamax']},\n",
    "    'mlp_name':{'values':['MLP','MLPnorm','MLPla']},\n",
    "#     'loss_name':{'values':['ce loss','dice loss']},\n",
    "    'active_fun':{'values':['ReLU','GELU','Softplus']},\n",
    "    'type_num':{\n",
    "        'values':[10,20,30,70,100,200,300]\n",
    "    },\n",
    "    'learning_rate':{\n",
    "        'distribution':'log_uniform_values',\n",
    "        'min':5e-5,\n",
    "        'max':0.0001\n",
    "    },\n",
    "    \n",
    "    'weight_decay':{\n",
    "        'distribution':'log_uniform_values',\n",
    "        'min':1e-5,\n",
    "        'max':0.0001\n",
    "    },\n",
    "    'loss_s_weight':{\n",
    "        'distribution':'q_uniform',\n",
    "        'q':1,\n",
    "        'min':1,\n",
    "        'max':3\n",
    "    },\n",
    "    'loss_r_weight':{\n",
    "        'distribution':'q_uniform',\n",
    "        'q':1,\n",
    "        'min':1,\n",
    "        'max':3\n",
    "    },\n",
    "#     'per_gpu_train_batch_size':{\n",
    "#         'distribution':'q_uniform',\n",
    "#         'q':4,\n",
    "#         'min':8,\n",
    "#         'max':16\n",
    "#     },\n",
    "#     'per_gpu_eval_batch_size':{\n",
    "#     'distribution':'q_uniform',\n",
    "#     'q':4,\n",
    "#     'min':8,\n",
    "#     'max':16\n",
    "#     },\n",
    "    'dropout_p':{\n",
    "        'distribution':'q_uniform',\n",
    "        'q':0.1,\n",
    "        'min':0.1,\n",
    "        'max':0.3\n",
    "    },\n",
    "#     'gradient_accumulation_steps':{\n",
    "#     'distribution':'q_uniform',\n",
    "#     'q':1,\n",
    "#     'min':1,\n",
    "#     'max':4\n",
    "#     },\n",
    "#     'max_grad_norm':{\n",
    "#     'distribution':'q_uniform',\n",
    "#     'q':1,\n",
    "#     'min':4,\n",
    "#     'max':5\n",
    "#     }\n",
    "})\n",
    "\n",
    "def main(args=None):\n",
    "    # Required parameters\n",
    "    if args == None:\n",
    "        args = Config_parser()\n",
    "    \n",
    "    # Setup CUDA, GPU & distributed training ########################################################\n",
    "    if args.local_rank == -1 or args.no_cuda:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        device = torch.device(\"cuda\", args.local_rank)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\")\n",
    "        args.n_gpu = 1\n",
    "    args.device = device\n",
    "    # Prepare task####################################################################################\n",
    "    args.task_name = args.task_name.lower()\n",
    "    processor = processors[args.task_name]()\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels1,num_labels2 = len(label_list[0]),len(label_list[1])\n",
    "    ###################################################################################################    \n",
    "    \n",
    "    # Load pretrained model and tokenizer\n",
    "    args.model_type = args.model_type.lower()\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "    config = config_class.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        finetuning_task=args.task_name,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None\n",
    "    )\n",
    "    config.output_hidden_states=True\n",
    "    tokenizer = tokenizer_class.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        do_lower_case=args.do_lower_case,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    \n",
    "    sweep_id=wandb.sweep(sweep_config,project='ETANET')\n",
    "    \n",
    "    #####################################################################################################\n",
    "\n",
    "    # Trainingr\n",
    "    if args.do_train:\n",
    "        print(\"--do train--\")\n",
    "        train_dataset= load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)\n",
    "#         assert 1==0\n",
    "        new_train_func = partial(train,config=config,args=args,train_dataset=train_dataset,tokenizer=tokenizer)\n",
    "        wandb.agent(sweep_id,new_train_func,count=10)\n",
    "#         global_step, tr_loss, best_steps = train(args, train_dataset, model, tokenizer)\n",
    "\n",
    "args = argparse.Namespace(data_dir=\"/kaggle/input/cassdataset\",\n",
    "                          model_type=\"bert\", model_name_or_path=\"bert-base-multilingual-cased\", \n",
    "                          task_name=\"fewfc\", output_dir=\"/kaggle/working/\",max_seq_length=128,max_steps=-1,loss_s_weight=1,loss_r_weight=1,\n",
    "                          no_cuda=False,per_gpu_train_batch_size=16,per_gpu_eval_batch_size=16,seed=100,dropout_p=0.1,\n",
    "                          fp16=False,gradient_accumulation_steps=1,bert_lr=2e-5,learning_rate=5e-5,weight_decay=0.001,\n",
    "                          adam_epsilon=1e-7,max_grad_norm=5.0,num_train_epochs=6,warmup_ratio=0.1,loss_name='ce loss',\n",
    "                          logging_steps=100,save_steps=100,eval_all_checkpoints=False,do_train=True,optim_type='AdamW',mlp_name='MLP',\n",
    "                          do_pretrain=False,do_eval=False,do_test=False,evaluate_during_training=True,span_size=3,relation_size=2,\n",
    "                          local_rank=-1,cache_dir='',do_lower_case=False,overwrite_cache=True,type_num=30,hidden_size=768,active_fun='ReLU')\n",
    "if __name__ == \"__main__\":\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
